# coding: utf-8

"""
    FlashArray REST API

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)

    The version of the OpenAPI document: 2.1
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json

from pydantic import BaseModel, ConfigDict, Field, StrictStr
from typing import Any, ClassVar, Dict, List, Optional
from pypureclient.flasharray.FA_2_1.models.offload_azure import OffloadAzure
from pypureclient.flasharray.FA_2_1.models.offload_nfs import OffloadNfs
from pypureclient.flasharray.FA_2_1.models.offload_s3 import OffloadS3
from pypureclient.flasharray.FA_2_1.models.space import Space
from typing import Optional, Set
from typing_extensions import Self

class Offload(BaseModel):
    """
    Offload
    """ # noqa: E501
    nfs: Optional[OffloadNfs] = Field(default=None, description="The NFS storage settings. Deprecated from version 6.6.0 onwards - Contact support for additional information.")
    s3: Optional[OffloadS3] = Field(default=None, description="The Amazon S3 storage settings.")
    azure: Optional[OffloadAzure] = Field(default=None, description="The Microsoft Azure Blob storage settings.")
    name: Optional[StrictStr] = Field(default=None, description="A user-specified name. The name must be locally unique and can be changed.")
    protocol: Optional[StrictStr] = Field(default=None, description="The type of offload. Valid values are `nfs` for Network File System, `s3` for Amazon S3, and `azure` for Microsoft Azure.")
    target_id: Optional[StrictStr] = Field(default=None, description="The unique ID for the offload target. When multiple connections to one offload target are created, they will each have distinct IDs but share the same target ID.")
    space: Optional[Space] = Field(default=None, description="Displays provisioned size and physical storage consumption information for the sum of all volumes connected to the specified host.")
    status: Optional[StrictStr] = Field(default=None, description="The connection status of the offload target. Valid values are `connecting`, `connected`, `disconnecting`, `not connected`, and `scanning`.  If set to `connected`, the array is connected to the offload target  and is functioning properly.  If set to `connecting`, the connection between the array and offload target is unhealthy,  possibly due to network issues. Check the network connectivity between the interfaces,  disconnect the array from the offload target, and then reconnect. If the issue persists,  contact Pure Storage Support.  If set to `not connected`, the offload app is not running and data  cannot be replicated to the offload targets. Contact Pure Storage Support.  If set to `scanning`,  a connection has been established between the array and offload target,  and the system is determining the state of the offload target.  Once the scan successfully completes, the status will change to `connected`.")
    __properties: ClassVar[List[str]] = ["nfs", "s3", "azure", "name", "protocol", "target_id", "space", "status"]

    model_config = ConfigDict(
        populate_by_name=True,
        validate_assignment=True,
        protected_namespaces=(),
    )


    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.model_dump(by_alias=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        # TODO: pydantic v2: use .model_dump_json(by_alias=True, exclude_unset=True) instead
        return json.dumps(self.to_dict())

    def to_dict(self, include_readonly: bool = False) -> Dict[str, Any]:
        """Return the dictionary representation of the model using alias.

        This has the following differences from calling pydantic's
        `self.model_dump(by_alias=True)`:

        * `None` is only added to the output dict for nullable fields that
          were set at model initialization. Other fields with value `None`
          are ignored.

        * OpenAPI `readOnly` fields are excluded, if `include_readonly` is `False`.
        """
        excluded_fields: Set[str] = set([
            "protocol",
            "target_id",
            "status",
        ])

        _dict = self.model_dump(
            by_alias=True,
            exclude=set() if include_readonly else excluded_fields,
            exclude_none=True,
        )
        # override the default output from pydantic by calling `to_dict()` of nfs
        if self.nfs and (include_readonly or "nfs" not in excluded_fields):
            _dict['nfs'] = self.nfs.to_dict()
        # override the default output from pydantic by calling `to_dict()` of s3
        if self.s3 and (include_readonly or "s3" not in excluded_fields):
            _dict['s3'] = self.s3.to_dict()
        # override the default output from pydantic by calling `to_dict()` of azure
        if self.azure and (include_readonly or "azure" not in excluded_fields):
            _dict['azure'] = self.azure.to_dict()
        # override the default output from pydantic by calling `to_dict()` of space
        if self.space and (include_readonly or "space" not in excluded_fields):
            _dict['space'] = self.space.to_dict()
        return _dict

    def __getitem__(self, key):
        return getattr(self, key)

    def __setitem__(self, key, value):
        setattr(self, key, value)

    def __delitem__(self, key):
        setattr(self, key, None)

    @classmethod
    def from_json(cls, json_str: str) -> Optional[Self]:
        """Create an instance of Offload from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    @classmethod
    def from_dict(cls, obj: Optional[Dict[str, Any]]) -> Optional[Self]:
        """Create an instance of Offload from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return cls.model_validate(obj)

        _obj = cls.model_construct(_fields_set=None, **{
            "nfs": OffloadNfs.from_dict(obj["nfs"]) if obj.get("nfs") is not None else None,
            "s3": OffloadS3.from_dict(obj["s3"]) if obj.get("s3") is not None else None,
            "azure": OffloadAzure.from_dict(obj["azure"]) if obj.get("azure") is not None else None,
            "name": obj.get("name"),
            "protocol": obj.get("protocol"),
            "target_id": obj.get("target_id"),
            "space": Space.from_dict(obj["space"]) if obj.get("space") is not None else None,
            "status": obj.get("status")
        })
        return _obj


