# coding: utf-8

"""
    FlashArray REST API

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)

    The version of the OpenAPI document: 2.51
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
from pypureclient.flasharray.common.models.context_v_50 import Context
from pypureclient.flasharray.common.models.fixed_reference_v_49 import FixedReference
from pypureclient.flasharray.common.models.lifecycle_rule_config_base_v_51 import LifecycleRuleConfigBase

import pprint
import re  # noqa: F401
import json
from typing import Set, Dict, Any

from typing import Optional

try:
    from pydantic.v1 import BaseModel, Field, StrictBool, StrictInt, StrictStr
except ModuleNotFoundError:
    from pydantic import BaseModel, Field, StrictBool, StrictInt, StrictStr
from pypureclient.flasharray.common.models.fixed_reference_with_type_v_49 import FixedReferenceWithType


class LifecycleRule(BaseModel):
    """
    LifecycleRule
    """
    id: Optional[StrictStr] = Field(default=None, description="A globally unique, system-generated ID. The ID cannot be modified and cannot refer to another resource.")
    name: Optional[StrictStr] = Field(default=None, description="A locally unique, system-generated name. The name cannot be modified.")
    context: Optional[FixedReferenceWithType] = Field(default=None, description="The context in which the operation was performed. Valid values include a reference to any array which is a member of the same fleet or to the fleet itself. Other parameters provided with the request, such as names of volumes or snapshots, are resolved relative to the provided `context`.")
    abort_incomplete_multipart_uploads_after: Optional[StrictInt] = Field(default=None, description="Duration of time after which incomplete multipart uploads will be aborted. Measured in milliseconds. Must be a multiple of 86400000 to represent a whole number of days.")
    keep_current_version_for: Optional[StrictInt] = Field(default=None, description="Time after which current versions will be marked expired. Measured in milliseconds. Must be a multiple of 86400000 to represent a whole number of days.")
    keep_current_version_until: Optional[StrictInt] = Field(default=None, description="Time after which current versions will be marked expired. Measured in milliseconds, time since epoch. Must be a valid date, accurate to day.")
    keep_previous_version_for: Optional[StrictInt] = Field(default=None, description="The time in milliseconds after which previous versions are marked expired. Must be a multiple of 86400000 to represent a whole number of days.")
    prefix: Optional[StrictStr] = Field(default=None, description="The object key prefix identifying one or more objects in the bucket. The maximum length is 1024 characters.")
    bucket: Optional[FixedReferenceWithType] = Field(default=None, description="The bucket which this lifecycle rule is targeting.")
    cleanup_expired_object_delete_marker: Optional[StrictBool] = Field(default=None, description="Returns a value of `true` if the expired object delete markers will be removed.")
    enabled: Optional[StrictBool] = Field(default=None, description="If set to `true`, this rule will be enabled.")
    rule_id: Optional[StrictStr] = Field(default=None, description="The identifier for the rule. It must be unique to the bucket. The maximum length is 255 characters. If not specified, an ID unique to the bucket is generated in the format `<platformName>RuleId<number>`, where `<number>` increments starting at 1.")
    __properties = ["id", "name", "context", "abort_incomplete_multipart_uploads_after", "keep_current_version_for", "keep_current_version_until", "keep_previous_version_for", "prefix", "bucket", "cleanup_expired_object_delete_marker", "enabled", "rule_id"]

    class Config:
        """Pydantic configuration"""
        allow_population_by_field_name = True
        validate_assignment = True

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.to_dict(include_readonly=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        return json.dumps(self.as_request_dict())

    def as_request_dict(self) -> Dict[str, Any]:
        return self.to_dict(include_readonly=False)

    def to_dict(self, include_readonly: bool=True) -> Dict[str, Any]:

        """Returns the dictionary representation of the model using alias"""
        excluded_fields: Set[str] = set()
        if not include_readonly:
            excluded_fields.update([
                "id",
                "name",
                "context",
                "cleanup_expired_object_delete_marker",
            ])
        none_fields: Set[str] = set()
        for _field in self.__fields__.keys():
            if super().__getattribute__(_field) is None:
                none_fields.add(_field)

        _dict = self.dict(by_alias=True, exclude=excluded_fields, exclude_none=True)
        # override the default output from pydantic by calling `to_dict()` of context
        if _include_in_dict('context', include_readonly, excluded_fields, none_fields):
            _dict['context'] = self.context.to_dict(include_readonly=include_readonly)
        # override the default output from pydantic by calling `to_dict()` of bucket
        if _include_in_dict('bucket', include_readonly, excluded_fields, none_fields):
            _dict['bucket'] = self.bucket.to_dict(include_readonly=include_readonly)
        return _dict

    def __getitem__(self, key):
        return super().__getattribute__(key)

    def __setitem__(self, key, value):
        setattr(self, key, value)

    def __delitem__(self, key):
        setattr(self, key, None)

    def __getattribute__(self, name: str) -> Any:
        _value = super().__getattribute__(name)
        if _value is None and name in self.__fields__.keys() and _should_raise_on_none():
            raise AttributeError
        return _value
    def __str__(self) -> str:
        return self.to_str()

    def __repr__(self) -> str:
        return self.to_str()

    @classmethod
    def from_json(cls, json_str: str) -> LifecycleRule:
        """Create an instance of LifecycleRule from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    @classmethod
    def from_dict(cls, obj: dict) -> LifecycleRule:
        """Create an instance of LifecycleRule from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return LifecycleRule.parse_obj(obj)

        _obj = LifecycleRule.construct(_fields_set=None, **{
            "id": obj.get("id"),
            "name": obj.get("name"),
            "context": FixedReferenceWithType.from_dict(obj.get("context")) if obj.get("context") is not None else None,
            "abort_incomplete_multipart_uploads_after": obj.get("abort_incomplete_multipart_uploads_after"),
            "keep_current_version_for": obj.get("keep_current_version_for"),
            "keep_current_version_until": obj.get("keep_current_version_until"),
            "keep_previous_version_for": obj.get("keep_previous_version_for"),
            "prefix": obj.get("prefix"),
            "bucket": FixedReferenceWithType.from_dict(obj.get("bucket")) if obj.get("bucket") is not None else None,
            "cleanup_expired_object_delete_marker": obj.get("cleanup_expired_object_delete_marker"),
            "enabled": obj.get("enabled"),
            "rule_id": obj.get("rule_id")
        })
        return _obj

def _should_raise_on_none() -> bool:
    import importlib
    _package = importlib.import_module(__package__)
    return _package._attribute_error_on_none

def _include_in_dict(name: str, include_readonly: bool, excluded_fields: Set[str], none_fields: Set[str]) -> bool:
    if name in none_fields:
        return False
    return (include_readonly or name not in excluded_fields)

