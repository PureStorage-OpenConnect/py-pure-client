# coding: utf-8

"""
    FlashArray REST API

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)

    The version of the OpenAPI document: 2.36
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json
from typing import Set, Dict, Any

from typing import Optional

try:
    from pydantic.v1 import BaseModel, Field, StrictStr
except ModuleNotFoundError:
    from pydantic import BaseModel, Field, StrictStr
from pypureclient.flasharray.FA_2_36.models.offload_azure import OffloadAzure
from pypureclient.flasharray.FA_2_36.models.offload_google_cloud import OffloadGoogleCloud
from pypureclient.flasharray.FA_2_36.models.offload_nfs import OffloadNfs
from pypureclient.flasharray.FA_2_36.models.offload_s3 import OffloadS3
from pypureclient.flasharray.FA_2_36.models.space import Space


class Offload(BaseModel):
    """
    Offload
    """
    azure: Optional[OffloadAzure] = Field(default=None, description="Microsoft Azure Blob storage settings.")
    google_cloud: Optional[OffloadGoogleCloud] = Field(default=None, alias="google-cloud", description="Google Cloud Storage settings.")
    nfs: Optional[OffloadNfs] = Field(default=None, description="NFS settings. Deprecated from version 6.6.0 onwards - Contact support for additional information.")
    s3: Optional[OffloadS3] = Field(default=None, description="S3 settings.")
    name: Optional[StrictStr] = Field(default=None, description="A user-specified name. The name must be locally unique and can be changed.")
    protocol: Optional[StrictStr] = Field(default=None, description="Type of offload. Valid values include `azure`, `google-cloud`, `nfs`, and `s3`.")
    space: Optional[Space] = None
    status: Optional[StrictStr] = Field(default=None, description="Offload status. Valid values are `connecting`, `connected`, `disconnecting`, `not connected`, and `scanning`.")
    target_id: Optional[StrictStr] = Field(default=None, description="Unique ID for the offload target. When multiple connections to one offload target are created, they each have distinct IDs but share the same `target_id`.")
    __properties = ["azure", "google-cloud", "nfs", "s3", "name", "protocol", "space", "status", "target_id"]

    class Config:
        """Pydantic configuration"""
        allow_population_by_field_name = True
        validate_assignment = True

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.to_dict(include_readonly=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        return json.dumps(self.as_request_dict())

    def as_request_dict(self) -> Dict[str, Any]:
        return self.to_dict(include_readonly=False)

    def to_dict(self, include_readonly: bool=True) -> Dict[str, Any]:

        """Returns the dictionary representation of the model using alias"""
        excluded_fields: Set[str] = set()
        if not include_readonly:
            excluded_fields.update([
                "protocol",
                "status",
                "target_id",
            ])
        none_fields: Set[str] = set()
        for _field in self.__fields__.keys():
            if super().__getattribute__(_field) is None:
                none_fields.add(_field)

        _dict = self.dict(by_alias=True, exclude=excluded_fields, exclude_none=True)
        # override the default output from pydantic by calling `to_dict()` of azure
        if _include_in_dict('azure', include_readonly, excluded_fields, none_fields):
            _dict['azure'] = self.azure.to_dict(include_readonly=include_readonly)
        # override the default output from pydantic by calling `to_dict()` of google_cloud
        if _include_in_dict('google_cloud', include_readonly, excluded_fields, none_fields):
            _dict['google-cloud'] = self.google_cloud.to_dict(include_readonly=include_readonly)
        # override the default output from pydantic by calling `to_dict()` of nfs
        if _include_in_dict('nfs', include_readonly, excluded_fields, none_fields):
            _dict['nfs'] = self.nfs.to_dict(include_readonly=include_readonly)
        # override the default output from pydantic by calling `to_dict()` of s3
        if _include_in_dict('s3', include_readonly, excluded_fields, none_fields):
            _dict['s3'] = self.s3.to_dict(include_readonly=include_readonly)
        # override the default output from pydantic by calling `to_dict()` of space
        if _include_in_dict('space', include_readonly, excluded_fields, none_fields):
            _dict['space'] = self.space.to_dict(include_readonly=include_readonly)
        return _dict

    def __getitem__(self, key):
        return super().__getattribute__(key)

    def __setitem__(self, key, value):
        setattr(self, key, value)

    def __delitem__(self, key):
        setattr(self, key, None)

    def __getattribute__(self, name: str) -> Any:
        _value = super().__getattribute__(name)
        if _value is None and name in self.__fields__.keys() and _should_raise_on_none():
            raise AttributeError
        return _value

    def __str__(self) -> str:
        return self.to_str()

    def __repr__(self) -> str:
        return self.to_str()

    @classmethod
    def from_json(cls, json_str: str) -> Offload:
        """Create an instance of Offload from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    @classmethod
    def from_dict(cls, obj: dict) -> Offload:
        """Create an instance of Offload from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return Offload.parse_obj(obj)

        _obj = Offload.construct(_fields_set=None, **{
            "azure": OffloadAzure.from_dict(obj.get("azure")) if obj.get("azure") is not None else None,
            "google_cloud": OffloadGoogleCloud.from_dict(obj.get("google-cloud")) if obj.get("google-cloud") is not None else None,
            "nfs": OffloadNfs.from_dict(obj.get("nfs")) if obj.get("nfs") is not None else None,
            "s3": OffloadS3.from_dict(obj.get("s3")) if obj.get("s3") is not None else None,
            "name": obj.get("name"),
            "protocol": obj.get("protocol"),
            "space": Space.from_dict(obj.get("space")) if obj.get("space") is not None else None,
            "status": obj.get("status"),
            "target_id": obj.get("target_id")
        })
        return _obj

def _should_raise_on_none() -> bool:
    import importlib
    _package = importlib.import_module(__package__)
    return _package._attribute_error_on_none

def _include_in_dict(name: str, include_readonly: bool, excluded_fields: Set[str], none_fields: Set[str]) -> bool:
    if name in none_fields:
        return False
    return (include_readonly or name not in excluded_fields)

