# coding: utf-8

"""
    FlashArray REST API

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)

    The version of the OpenAPI document: 2.37
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json
from typing import Set, Dict, Any

from typing import Optional

try:
    from pydantic.v1 import BaseModel, Field, StrictStr
except ModuleNotFoundError:
    from pydantic import BaseModel, Field, StrictStr


class OffloadS3(BaseModel):
    """
    OffloadS3
    """
    access_key_id: Optional[StrictStr] = Field(default=None, description="The access key ID of the AWS account used to create a connection between the array and an Amazon S3 offload target. The access key ID is 20 characters in length and is only accepted when creating the connection between the array and the S3 offload target. The `access_key_id`, `secret_access_key`, and `bucket` parameters must be set together.")
    auth_region: Optional[StrictStr] = Field(default=None, description="The region that will be used for initial authentication request. This parameter is optional and should be used only when region autodetection fails.")
    bucket: Optional[StrictStr] = Field(default=None, description="The name of the Amazon S3 bucket to where the data will be offloaded. Grant basic read and write ACL permissions to the bucket, and enable default (server-side) encryption for the bucket. Also verify that the bucket is empty of all objects and does not have any lifecycle policies. The `access_key_id`, `secret_access_key`, and `bucket` parameters must be set together.")
    placement_strategy: Optional[StrictStr] = Field(default=None, description="The storage placement strategy used for the dynamic placement of data in an Amazon S3 offload target. Valid values are `aws-intelligent-tiering`, `aws-standard-class`, and `retention-based`. If set to `aws-intelligent-tiering`, data is stored in the Amazon S3 INTELLIGENT_TIERING storage class regardless of the retention period. If set to `aws-standard-access`, the data is stored in the Amazon S3 STANDARD storage class regardless of the retention period. If set to `retention-based`, the data for protection groups with longer retention periods is placed in the Amazon S3 STANDARD_IA (infrequently accessed, more cost-effective) storage class. All other data is placed in the STANDARD storage class. When the array is initially connected to an S3 offload target, `placement_strategy` is automatically set to `retention-based`. The `placement_strategy` or `uri` parameter is required, but they cannot be set together.")
    profile: Optional[StrictStr] = Field(default=None, description="The offload target profile that will be selected for this target. This option allows more granular configuration for the target on top of the `protocol` parameter. Values include `s3-aws`, `s3-flashblade`, `s3-scality-ring`, `s3-wasabi-pay-as-you-go`, `s3-wasabi-rcs`, and `s3-other`.")
    secret_access_key: Optional[StrictStr] = Field(default=None, description="The secret access key that goes with the access key ID (`access_key_id`) of the AWS account. The secret access key is 40 characters in length is only accepted when creating the connection between the array and the S3 offload target. The `access_key_id`, `secret_access_key`, and `bucket` parameters must be set together.")
    uri: Optional[StrictStr] = Field(default=None, description="The URI used to create a connection between the array and a non-AWS S3 offload target. Storage placement strategies are not supported for non-AWS S3 offload targets. Both the HTTP and HTTPS protocols are allowed.")
    __properties = ["access_key_id", "auth_region", "bucket", "placement_strategy", "profile", "secret_access_key", "uri"]

    class Config:
        """Pydantic configuration"""
        allow_population_by_field_name = True
        validate_assignment = True

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.to_dict(include_readonly=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        return json.dumps(self.as_request_dict())

    def as_request_dict(self) -> Dict[str, Any]:
        return self.to_dict(include_readonly=False)

    def to_dict(self, include_readonly: bool=True) -> Dict[str, Any]:

        """Returns the dictionary representation of the model using alias"""
        excluded_fields: Set[str] = set()
        if not include_readonly:
            excluded_fields.update([
            ])
        none_fields: Set[str] = set()
        for _field in self.__fields__.keys():
            if super().__getattribute__(_field) is None:
                none_fields.add(_field)

        _dict = self.dict(by_alias=True, exclude=excluded_fields, exclude_none=True)
        return _dict

    def __getitem__(self, key):
        return super().__getattribute__(key)

    def __setitem__(self, key, value):
        setattr(self, key, value)

    def __delitem__(self, key):
        setattr(self, key, None)

    def __getattribute__(self, name: str) -> Any:
        _value = super().__getattribute__(name)
        if _value is None and name in self.__fields__.keys() and _should_raise_on_none():
            raise AttributeError
        return _value

    def __str__(self) -> str:
        return self.to_str()

    def __repr__(self) -> str:
        return self.to_str()

    @classmethod
    def from_json(cls, json_str: str) -> OffloadS3:
        """Create an instance of OffloadS3 from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    @classmethod
    def from_dict(cls, obj: dict) -> OffloadS3:
        """Create an instance of OffloadS3 from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return OffloadS3.parse_obj(obj)

        _obj = OffloadS3.construct(_fields_set=None, **{
            "access_key_id": obj.get("access_key_id"),
            "auth_region": obj.get("auth_region"),
            "bucket": obj.get("bucket"),
            "placement_strategy": obj.get("placement_strategy"),
            "profile": obj.get("profile"),
            "secret_access_key": obj.get("secret_access_key"),
            "uri": obj.get("uri")
        })
        return _obj

def _should_raise_on_none() -> bool:
    import importlib
    _package = importlib.import_module(__package__)
    return _package._attribute_error_on_none

def _include_in_dict(name: str, include_readonly: bool, excluded_fields: Set[str], none_fields: Set[str]) -> bool:
    if name in none_fields:
        return False
    return (include_readonly or name not in excluded_fields)

