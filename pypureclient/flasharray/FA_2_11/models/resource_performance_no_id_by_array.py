# coding: utf-8

"""
    FlashArray REST API

    No description provided (generated by Openapi Generator https://github.com/openapitools/openapi-generator)

    The version of the OpenAPI document: 2.11
    Generated by OpenAPI Generator (https://openapi-generator.tech)

    Do not edit the class manually.
"""  # noqa: E501


from __future__ import annotations
import pprint
import re  # noqa: F401
import json
from typing import Set, Dict, Any

from typing import Optional, Union
from pydantic import BaseModel, Field, StrictInt, StrictStr, confloat, conint
from pypureclient.flasharray.FA_2_11.models.resource import Resource


class ResourcePerformanceNoIdByArray(BaseModel):
    """
    ResourcePerformanceNoIdByArray
    """
    bytes_per_mirrored_write: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The average I/O size per mirrored write, measured in bytes.")
    bytes_per_op: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The average I/O size for both read and write (all) operations.")
    bytes_per_read: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The average I/O size per read, measured in bytes.")
    bytes_per_write: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The average I/O size per write, measured in bytes.")
    mirrored_write_bytes_per_sec: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The number of mirrored bytes written per second.")
    mirrored_writes_per_sec: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The number of mirrored writes per second.")
    qos_rate_limit_usec_per_mirrored_write_op: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The average time it takes the array to process a mirrored I/O write request, measured in microseconds.")
    qos_rate_limit_usec_per_read_op: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The average time spent waiting due to QoS rate limiting for a read request, measured in microseconds.")
    qos_rate_limit_usec_per_write_op: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The average time that a write I/O request spends waiting as a result of the volume reaching its QoS bandwidth limit, measured in microseconds.")
    queue_usec_per_mirrored_write_op: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The average time that a mirrored write I/O request spends in the array waiting to be served, measured in microseconds.")
    queue_usec_per_read_op: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The average time that a read I/O request spends in the array waiting to be served, measured in microseconds.")
    queue_usec_per_write_op: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The average time that a write I/O request spends in the array waiting to be served, measured in microseconds.")
    read_bytes_per_sec: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The number of bytes read per second.")
    reads_per_sec: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The number of read requests processed per second.")
    san_usec_per_mirrored_write_op: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The average time required to transfer data from the initiator to the array for a mirrored write request, measured in microseconds.")
    san_usec_per_read_op: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The average time required to transfer data from the array to the initiator for a read request, measured in microseconds.")
    san_usec_per_write_op: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The average time required to transfer data from the initiator to the array for a write request, measured in microseconds.")
    service_usec_per_mirrored_write_op: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The average time required for the array to service a mirrored write request, measured in microseconds.")
    service_usec_per_read_op: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The average time required for the array to service a read request, measured in microseconds.")
    service_usec_per_read_op_cache_reduction: Optional[Union[confloat(le=1, ge=0, strict=True), conint(le=1, ge=0, strict=True)]] = Field(default=None, description="The percentage reduction in `service_usec_per_read_op` due to data cache hits. For example, a value of 0.25 indicates that the value of `service_usec_per_read_op` is 25&#37; lower than it would have been without any data cache hits.")
    service_usec_per_write_op: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The average time required for the array to service a write request, measured in microseconds.")
    time: Optional[StrictInt] = Field(default=None, description="The time when the sample performance data was taken, measured in milliseconds since the UNIX epoch.")
    usec_per_mirrored_write_op: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The average time it takes the array to process a mirrored I/O write request, measured in microseconds. Beginning in Purity 6.3.14 and 6.4.10 and later, including later major versions (6.5.x, 6.6.x and beyond), queue time is included. The average time does not include SAN time or QoS rate limit time.")
    usec_per_read_op: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The average time it takes the array to process an I/O read request, measured in microseconds. Beginning in Purity 6.3.14 and 6.4.10 and later, including later major versions (6.5.x, 6.6.x and beyond), queue time is included. The average time does not include SAN time or QoS rate limit time.")
    usec_per_write_op: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The average time it takes the array to process an I/O write request, measured in microseconds. Beginning in Purity 6.3.14 and 6.4.10 and later, including later major versions (6.5.x, 6.6.x and beyond), queue time is included. The average time does not include SAN time or QoS rate limit time.")
    write_bytes_per_sec: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The number of bytes written per second.")
    writes_per_sec: Optional[conint(strict=True, ge=0)] = Field(default=None, description="The number of write requests processed per second.")
    name: Optional[StrictStr] = Field(default=None, description="A user-specified name. The name must be locally unique and can be changed.")
    array: Optional[Resource] = Field(default=None, description="The array on which the performance metrics were recorded.")
    __properties = ["bytes_per_mirrored_write", "bytes_per_op", "bytes_per_read", "bytes_per_write", "mirrored_write_bytes_per_sec", "mirrored_writes_per_sec", "qos_rate_limit_usec_per_mirrored_write_op", "qos_rate_limit_usec_per_read_op", "qos_rate_limit_usec_per_write_op", "queue_usec_per_mirrored_write_op", "queue_usec_per_read_op", "queue_usec_per_write_op", "read_bytes_per_sec", "reads_per_sec", "san_usec_per_mirrored_write_op", "san_usec_per_read_op", "san_usec_per_write_op", "service_usec_per_mirrored_write_op", "service_usec_per_read_op", "service_usec_per_read_op_cache_reduction", "service_usec_per_write_op", "time", "usec_per_mirrored_write_op", "usec_per_read_op", "usec_per_write_op", "write_bytes_per_sec", "writes_per_sec", "name", "array"]

    class Config:
        """Pydantic configuration"""
        allow_population_by_field_name = True
        validate_assignment = True

    def to_str(self) -> str:
        """Returns the string representation of the model using alias"""
        return pprint.pformat(self.to_dict(include_readonly=True))

    def to_json(self) -> str:
        """Returns the JSON representation of the model using alias"""
        return json.dumps(self.as_request_dict())

    def as_request_dict(self) -> Dict[str, Any]:
        return self.to_dict(include_readonly=False)

    def to_dict(self, include_readonly: bool=True) -> Dict[str, Any]:

        """Returns the dictionary representation of the model using alias"""
        excluded_fields: Set[str] = set()
        if not include_readonly:
            excluded_fields.update([
                "bytes_per_mirrored_write",
                "bytes_per_op",
                "bytes_per_read",
                "bytes_per_write",
                "mirrored_write_bytes_per_sec",
                "mirrored_writes_per_sec",
                "qos_rate_limit_usec_per_mirrored_write_op",
                "qos_rate_limit_usec_per_read_op",
                "qos_rate_limit_usec_per_write_op",
                "queue_usec_per_mirrored_write_op",
                "queue_usec_per_read_op",
                "queue_usec_per_write_op",
                "read_bytes_per_sec",
                "reads_per_sec",
                "san_usec_per_mirrored_write_op",
                "san_usec_per_read_op",
                "san_usec_per_write_op",
                "service_usec_per_mirrored_write_op",
                "service_usec_per_read_op",
                "service_usec_per_write_op",
                "time",
                "usec_per_mirrored_write_op",
                "usec_per_read_op",
                "usec_per_write_op",
                "write_bytes_per_sec",
                "writes_per_sec",
            ])
        none_fields: Set[str] = set()
        for _field in self.__fields__.keys():
            if super().__getattribute__(_field) is None:
                none_fields.add(_field)

        _dict = self.dict(by_alias=True, exclude=excluded_fields, exclude_none=True)
        # override the default output from pydantic by calling `to_dict()` of array
        if _include_in_dict('array', include_readonly, excluded_fields, none_fields):
            _dict['array'] = self.array.to_dict(include_readonly=include_readonly)
        return _dict

    def __getitem__(self, key):
        return super().__getattribute__(key)

    def __setitem__(self, key, value):
        setattr(self, key, value)

    def __delitem__(self, key):
        setattr(self, key, None)

    def __getattribute__(self, name: str) -> Any:
        _value = super().__getattribute__(name)
        if _value is None and name in self.__fields__.keys() and _should_raise_on_none():
            raise AttributeError
        return _value

    def __str__(self) -> str:
        return self.to_str()

    def __repr__(self) -> str:
        return self.to_str()

    @classmethod
    def from_json(cls, json_str: str) -> ResourcePerformanceNoIdByArray:
        """Create an instance of ResourcePerformanceNoIdByArray from a JSON string"""
        return cls.from_dict(json.loads(json_str))

    @classmethod
    def from_dict(cls, obj: dict) -> ResourcePerformanceNoIdByArray:
        """Create an instance of ResourcePerformanceNoIdByArray from a dict"""
        if obj is None:
            return None

        if not isinstance(obj, dict):
            return ResourcePerformanceNoIdByArray.parse_obj(obj)

        _obj = ResourcePerformanceNoIdByArray.construct(_fields_set=None, **{
            "bytes_per_mirrored_write": obj.get("bytes_per_mirrored_write"),
            "bytes_per_op": obj.get("bytes_per_op"),
            "bytes_per_read": obj.get("bytes_per_read"),
            "bytes_per_write": obj.get("bytes_per_write"),
            "mirrored_write_bytes_per_sec": obj.get("mirrored_write_bytes_per_sec"),
            "mirrored_writes_per_sec": obj.get("mirrored_writes_per_sec"),
            "qos_rate_limit_usec_per_mirrored_write_op": obj.get("qos_rate_limit_usec_per_mirrored_write_op"),
            "qos_rate_limit_usec_per_read_op": obj.get("qos_rate_limit_usec_per_read_op"),
            "qos_rate_limit_usec_per_write_op": obj.get("qos_rate_limit_usec_per_write_op"),
            "queue_usec_per_mirrored_write_op": obj.get("queue_usec_per_mirrored_write_op"),
            "queue_usec_per_read_op": obj.get("queue_usec_per_read_op"),
            "queue_usec_per_write_op": obj.get("queue_usec_per_write_op"),
            "read_bytes_per_sec": obj.get("read_bytes_per_sec"),
            "reads_per_sec": obj.get("reads_per_sec"),
            "san_usec_per_mirrored_write_op": obj.get("san_usec_per_mirrored_write_op"),
            "san_usec_per_read_op": obj.get("san_usec_per_read_op"),
            "san_usec_per_write_op": obj.get("san_usec_per_write_op"),
            "service_usec_per_mirrored_write_op": obj.get("service_usec_per_mirrored_write_op"),
            "service_usec_per_read_op": obj.get("service_usec_per_read_op"),
            "service_usec_per_read_op_cache_reduction": obj.get("service_usec_per_read_op_cache_reduction"),
            "service_usec_per_write_op": obj.get("service_usec_per_write_op"),
            "time": obj.get("time"),
            "usec_per_mirrored_write_op": obj.get("usec_per_mirrored_write_op"),
            "usec_per_read_op": obj.get("usec_per_read_op"),
            "usec_per_write_op": obj.get("usec_per_write_op"),
            "write_bytes_per_sec": obj.get("write_bytes_per_sec"),
            "writes_per_sec": obj.get("writes_per_sec"),
            "name": obj.get("name"),
            "array": Resource.from_dict(obj.get("array")) if obj.get("array") is not None else None
        })
        return _obj

def _should_raise_on_none() -> bool:
    import importlib
    _package = importlib.import_module(__package__)
    return _package._attribute_error_on_none

def _include_in_dict(name: str, include_readonly: bool, excluded_fields: Set[str], none_fields: Set[str]) -> bool:
    if name in none_fields:
        return False
    return (include_readonly or name not in excluded_fields)

